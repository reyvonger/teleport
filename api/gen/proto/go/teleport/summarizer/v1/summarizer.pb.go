// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: teleport/summarizer/v1/summarizer.proto

package summarizerv1

import (
	v1 "github.com/gravitational/teleport/api/gen/proto/go/teleport/header/v1"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// InferenceModel resource describes a model and provider-specific parameters.
type InferenceModel struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Metadata      *v1.Metadata           `protobuf:"bytes,1,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *InferenceModelSpec    `protobuf:"bytes,2,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceModel) Reset() {
	*x = InferenceModel{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceModel) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceModel) ProtoMessage() {}

func (x *InferenceModel) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceModel.ProtoReflect.Descriptor instead.
func (*InferenceModel) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{0}
}

func (x *InferenceModel) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferenceModel) GetSpec() *InferenceModelSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferenceModelSpec defines the model and provider-specific parameters.
type InferenceModelSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Provider:
	//
	//	*InferenceModelSpec_Bedrock
	//	*InferenceModelSpec_Openai
	Provider isInferenceModelSpec_Provider `protobuf_oneof:"provider"`
	// Budget is post-MVP, optional for now.
	Budget        *Budget `protobuf:"bytes,3,opt,name=budget,proto3" json:"budget,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceModelSpec) Reset() {
	*x = InferenceModelSpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceModelSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceModelSpec) ProtoMessage() {}

func (x *InferenceModelSpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceModelSpec.ProtoReflect.Descriptor instead.
func (*InferenceModelSpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{1}
}

func (x *InferenceModelSpec) GetProvider() isInferenceModelSpec_Provider {
	if x != nil {
		return x.Provider
	}
	return nil
}

func (x *InferenceModelSpec) GetBedrock() *BedrockProvider {
	if x != nil {
		if x, ok := x.Provider.(*InferenceModelSpec_Bedrock); ok {
			return x.Bedrock
		}
	}
	return nil
}

func (x *InferenceModelSpec) GetOpenai() *OpenAIProvider {
	if x != nil {
		if x, ok := x.Provider.(*InferenceModelSpec_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

func (x *InferenceModelSpec) GetBudget() *Budget {
	if x != nil {
		return x.Budget
	}
	return nil
}

type isInferenceModelSpec_Provider interface {
	isInferenceModelSpec_Provider()
}

type InferenceModelSpec_Bedrock struct {
	Bedrock *BedrockProvider `protobuf:"bytes,1,opt,name=bedrock,proto3,oneof"`
}

type InferenceModelSpec_Openai struct {
	Openai *OpenAIProvider `protobuf:"bytes,2,opt,name=openai,proto3,oneof"` // Add more providers here in the future.
}

func (*InferenceModelSpec_Bedrock) isInferenceModelSpec_Provider() {}

func (*InferenceModelSpec_Openai) isInferenceModelSpec_Provider() {}

// Bedrock provider-specific parameters.
type BedrockProvider struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	BedrockModelId string                 `protobuf:"bytes,1,opt,name=bedrock_model_id,json=bedrockModelId,proto3" json:"bedrock_model_id,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *BedrockProvider) Reset() {
	*x = BedrockProvider{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BedrockProvider) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BedrockProvider) ProtoMessage() {}

func (x *BedrockProvider) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BedrockProvider.ProtoReflect.Descriptor instead.
func (*BedrockProvider) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{2}
}

func (x *BedrockProvider) GetBedrockModelId() string {
	if x != nil {
		return x.BedrockModelId
	}
	return ""
}

// OpenAI provider-specific parameters.
type OpenAIProvider struct {
	state           protoimpl.MessageState `protogen:"open.v1"`
	OpenaiModelId   string                 `protobuf:"bytes,1,opt,name=openai_model_id,json=openaiModelId,proto3" json:"openai_model_id,omitempty"`
	Temperature     float64                `protobuf:"fixed64,2,opt,name=temperature,proto3" json:"temperature,omitempty"`
	ApiKeySecretRef string                 `protobuf:"bytes,3,opt,name=api_key_secret_ref,json=apiKeySecretRef,proto3" json:"api_key_secret_ref,omitempty"`
	BaseUrl         string                 `protobuf:"bytes,4,opt,name=base_url,json=baseUrl,proto3" json:"base_url,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *OpenAIProvider) Reset() {
	*x = OpenAIProvider{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OpenAIProvider) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OpenAIProvider) ProtoMessage() {}

func (x *OpenAIProvider) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OpenAIProvider.ProtoReflect.Descriptor instead.
func (*OpenAIProvider) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{3}
}

func (x *OpenAIProvider) GetOpenaiModelId() string {
	if x != nil {
		return x.OpenaiModelId
	}
	return ""
}

func (x *OpenAIProvider) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *OpenAIProvider) GetApiKeySecretRef() string {
	if x != nil {
		return x.ApiKeySecretRef
	}
	return ""
}

func (x *OpenAIProvider) GetBaseUrl() string {
	if x != nil {
		return x.BaseUrl
	}
	return ""
}

// Budget for inference model usage (post-MVP).
type Budget struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TimePeriod    string                 `protobuf:"bytes,1,opt,name=time_period,json=timePeriod,proto3" json:"time_period,omitempty"` // e.g., "1mo", "1d"
	InputTokens   int64                  `protobuf:"varint,2,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`
	OutputTokens  int64                  `protobuf:"varint,3,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Budget) Reset() {
	*x = Budget{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Budget) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Budget) ProtoMessage() {}

func (x *Budget) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Budget.ProtoReflect.Descriptor instead.
func (*Budget) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{4}
}

func (x *Budget) GetTimePeriod() string {
	if x != nil {
		return x.TimePeriod
	}
	return ""
}

func (x *Budget) GetInputTokens() int64 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *Budget) GetOutputTokens() int64 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

// InferenceSecret resource stores provider secrets.
type InferenceSecret struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Metadata      *v1.Metadata           `protobuf:"bytes,1,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *InferenceSecretSpec   `protobuf:"bytes,2,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceSecret) Reset() {
	*x = InferenceSecret{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceSecret) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceSecret) ProtoMessage() {}

func (x *InferenceSecret) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceSecret.ProtoReflect.Descriptor instead.
func (*InferenceSecret) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{5}
}

func (x *InferenceSecret) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferenceSecret) GetSpec() *InferenceSecretSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferenceSecretSpec defines the secret value for the inference model.
type InferenceSecretSpec struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Value         string                 `protobuf:"bytes,1,opt,name=value,proto3" json:"value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceSecretSpec) Reset() {
	*x = InferenceSecretSpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceSecretSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceSecretSpec) ProtoMessage() {}

func (x *InferenceSecretSpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceSecretSpec.ProtoReflect.Descriptor instead.
func (*InferenceSecretSpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{6}
}

func (x *InferenceSecretSpec) GetValue() string {
	if x != nil {
		return x.Value
	}
	return ""
}

// InferencePolicy resource binds sessions to summarizers.
type InferencePolicy struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Metadata      *v1.Metadata           `protobuf:"bytes,1,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *InferencePolicySpec   `protobuf:"bytes,2,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferencePolicy) Reset() {
	*x = InferencePolicy{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferencePolicy) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferencePolicy) ProtoMessage() {}

func (x *InferencePolicy) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferencePolicy.ProtoReflect.Descriptor instead.
func (*InferencePolicy) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{7}
}

func (x *InferencePolicy) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferencePolicy) GetSpec() *InferencePolicySpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferencePolicySpec defines the policy for session summarization.
type InferencePolicySpec struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Kinds         []string               `protobuf:"bytes,1,rep,name=kinds,proto3" json:"kinds,omitempty"`   // Session kinds, e.g., "ssh", "kube", "db"
	Filter        string                 `protobuf:"bytes,2,opt,name=filter,proto3" json:"filter,omitempty"` // Optional filter expression
	Model         string                 `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`   // Name of the inference model to use
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferencePolicySpec) Reset() {
	*x = InferencePolicySpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferencePolicySpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferencePolicySpec) ProtoMessage() {}

func (x *InferencePolicySpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferencePolicySpec.ProtoReflect.Descriptor instead.
func (*InferencePolicySpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{8}
}

func (x *InferencePolicySpec) GetKinds() []string {
	if x != nil {
		return x.Kinds
	}
	return nil
}

func (x *InferencePolicySpec) GetFilter() string {
	if x != nil {
		return x.Filter
	}
	return ""
}

func (x *InferencePolicySpec) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

var File_teleport_summarizer_v1_summarizer_proto protoreflect.FileDescriptor

const file_teleport_summarizer_v1_summarizer_proto_rawDesc = "" +
	"\n" +
	"'teleport/summarizer/v1/summarizer.proto\x12\x16teleport.summarizer.v1\x1a!teleport/header/v1/metadata.proto\"\x8a\x01\n" +
	"\x0eInferenceModel\x128\n" +
	"\bmetadata\x18\x01 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12>\n" +
	"\x04spec\x18\x02 \x01(\v2*.teleport.summarizer.v1.InferenceModelSpecR\x04spec\"\xdf\x01\n" +
	"\x12InferenceModelSpec\x12C\n" +
	"\abedrock\x18\x01 \x01(\v2'.teleport.summarizer.v1.BedrockProviderH\x00R\abedrock\x12@\n" +
	"\x06openai\x18\x02 \x01(\v2&.teleport.summarizer.v1.OpenAIProviderH\x00R\x06openai\x126\n" +
	"\x06budget\x18\x03 \x01(\v2\x1e.teleport.summarizer.v1.BudgetR\x06budgetB\n" +
	"\n" +
	"\bprovider\";\n" +
	"\x0fBedrockProvider\x12(\n" +
	"\x10bedrock_model_id\x18\x01 \x01(\tR\x0ebedrockModelId\"\xa2\x01\n" +
	"\x0eOpenAIProvider\x12&\n" +
	"\x0fopenai_model_id\x18\x01 \x01(\tR\ropenaiModelId\x12 \n" +
	"\vtemperature\x18\x02 \x01(\x01R\vtemperature\x12+\n" +
	"\x12api_key_secret_ref\x18\x03 \x01(\tR\x0fapiKeySecretRef\x12\x19\n" +
	"\bbase_url\x18\x04 \x01(\tR\abaseUrl\"q\n" +
	"\x06Budget\x12\x1f\n" +
	"\vtime_period\x18\x01 \x01(\tR\n" +
	"timePeriod\x12!\n" +
	"\finput_tokens\x18\x02 \x01(\x03R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\x03 \x01(\x03R\foutputTokens\"\x8c\x01\n" +
	"\x0fInferenceSecret\x128\n" +
	"\bmetadata\x18\x01 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12?\n" +
	"\x04spec\x18\x02 \x01(\v2+.teleport.summarizer.v1.InferenceSecretSpecR\x04spec\"+\n" +
	"\x13InferenceSecretSpec\x12\x14\n" +
	"\x05value\x18\x01 \x01(\tR\x05value\"\x8c\x01\n" +
	"\x0fInferencePolicy\x128\n" +
	"\bmetadata\x18\x01 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12?\n" +
	"\x04spec\x18\x02 \x01(\v2+.teleport.summarizer.v1.InferencePolicySpecR\x04spec\"Y\n" +
	"\x13InferencePolicySpec\x12\x14\n" +
	"\x05kinds\x18\x01 \x03(\tR\x05kinds\x12\x16\n" +
	"\x06filter\x18\x02 \x01(\tR\x06filter\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05modelBXZVgithub.com/gravitational/teleport/api/gen/proto/go/teleport/summarizer/v1;summarizerv1b\x06proto3"

var (
	file_teleport_summarizer_v1_summarizer_proto_rawDescOnce sync.Once
	file_teleport_summarizer_v1_summarizer_proto_rawDescData []byte
)

func file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP() []byte {
	file_teleport_summarizer_v1_summarizer_proto_rawDescOnce.Do(func() {
		file_teleport_summarizer_v1_summarizer_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_teleport_summarizer_v1_summarizer_proto_rawDesc), len(file_teleport_summarizer_v1_summarizer_proto_rawDesc)))
	})
	return file_teleport_summarizer_v1_summarizer_proto_rawDescData
}

var file_teleport_summarizer_v1_summarizer_proto_msgTypes = make([]protoimpl.MessageInfo, 9)
var file_teleport_summarizer_v1_summarizer_proto_goTypes = []any{
	(*InferenceModel)(nil),      // 0: teleport.summarizer.v1.InferenceModel
	(*InferenceModelSpec)(nil),  // 1: teleport.summarizer.v1.InferenceModelSpec
	(*BedrockProvider)(nil),     // 2: teleport.summarizer.v1.BedrockProvider
	(*OpenAIProvider)(nil),      // 3: teleport.summarizer.v1.OpenAIProvider
	(*Budget)(nil),              // 4: teleport.summarizer.v1.Budget
	(*InferenceSecret)(nil),     // 5: teleport.summarizer.v1.InferenceSecret
	(*InferenceSecretSpec)(nil), // 6: teleport.summarizer.v1.InferenceSecretSpec
	(*InferencePolicy)(nil),     // 7: teleport.summarizer.v1.InferencePolicy
	(*InferencePolicySpec)(nil), // 8: teleport.summarizer.v1.InferencePolicySpec
	(*v1.Metadata)(nil),         // 9: teleport.header.v1.Metadata
}
var file_teleport_summarizer_v1_summarizer_proto_depIdxs = []int32{
	9, // 0: teleport.summarizer.v1.InferenceModel.metadata:type_name -> teleport.header.v1.Metadata
	1, // 1: teleport.summarizer.v1.InferenceModel.spec:type_name -> teleport.summarizer.v1.InferenceModelSpec
	2, // 2: teleport.summarizer.v1.InferenceModelSpec.bedrock:type_name -> teleport.summarizer.v1.BedrockProvider
	3, // 3: teleport.summarizer.v1.InferenceModelSpec.openai:type_name -> teleport.summarizer.v1.OpenAIProvider
	4, // 4: teleport.summarizer.v1.InferenceModelSpec.budget:type_name -> teleport.summarizer.v1.Budget
	9, // 5: teleport.summarizer.v1.InferenceSecret.metadata:type_name -> teleport.header.v1.Metadata
	6, // 6: teleport.summarizer.v1.InferenceSecret.spec:type_name -> teleport.summarizer.v1.InferenceSecretSpec
	9, // 7: teleport.summarizer.v1.InferencePolicy.metadata:type_name -> teleport.header.v1.Metadata
	8, // 8: teleport.summarizer.v1.InferencePolicy.spec:type_name -> teleport.summarizer.v1.InferencePolicySpec
	9, // [9:9] is the sub-list for method output_type
	9, // [9:9] is the sub-list for method input_type
	9, // [9:9] is the sub-list for extension type_name
	9, // [9:9] is the sub-list for extension extendee
	0, // [0:9] is the sub-list for field type_name
}

func init() { file_teleport_summarizer_v1_summarizer_proto_init() }
func file_teleport_summarizer_v1_summarizer_proto_init() {
	if File_teleport_summarizer_v1_summarizer_proto != nil {
		return
	}
	file_teleport_summarizer_v1_summarizer_proto_msgTypes[1].OneofWrappers = []any{
		(*InferenceModelSpec_Bedrock)(nil),
		(*InferenceModelSpec_Openai)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_teleport_summarizer_v1_summarizer_proto_rawDesc), len(file_teleport_summarizer_v1_summarizer_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   9,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_teleport_summarizer_v1_summarizer_proto_goTypes,
		DependencyIndexes: file_teleport_summarizer_v1_summarizer_proto_depIdxs,
		MessageInfos:      file_teleport_summarizer_v1_summarizer_proto_msgTypes,
	}.Build()
	File_teleport_summarizer_v1_summarizer_proto = out.File
	file_teleport_summarizer_v1_summarizer_proto_goTypes = nil
	file_teleport_summarizer_v1_summarizer_proto_depIdxs = nil
}
